---
layout: about
title: About
permalink: /
subtitle: <a href='#'>Affiliations</a>. Address. Contacts. Moto. Etc.

profile:
  align: left
  image: professional_reflection.jpg
  image_circular: true # crops the image to make it circular
  more_info: >
    <p>555 your office number</p>
    <p>123 your address street</p>
    <p>Your City, State 12345</p>


news: false # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
more: false

research_interest: Research Interest
more_title: More About Me
---

I am broadly interested in **reasoning**, which (IMHO) is a key aspect of human intelligence that sets us apart from other species. In the realm of reasoning, I've worked on:
- **Building general-purpose verifier** through rationale extraction from unlabelled data to provide process supervision during reasoning <a href="/publications/#Rationalyst">[1]</a>
- **Logical reasoning** that uses theorem prover [Lean](https://lean-lang.org/) to help with the reasoning process <a href="/publications/#lean">[2]</a>
- **Investigating the effectiveness of CoT prompting** across 100+ papers and 20 datasets and discovering CoT benefits mainly math/symbolic reasoning tasks <a href="/publications/#cot">[3]</a>
- **Decompositional entailment** that formulates a consistent and theoretically grounded approach to annotating decompositional entailment dataset <a href="/publications/#decompos">[4]</a>


I'm also interested in the **self-improvement** capability of LLMs. If we begin with the “end” (superintelligence/AGI) in mind, relying on human input won't get us there. We need to teach models to interact with the environment and self-improve. Specifically, I've worked on:
- **Understanding the reason** that prevents LLM from effective self-improvement <a href="/publications/#self-[in]correct">[5]</a>
- **Probing the limits** of self-improvement


Moreover, the role of (synthetic) training data and post-training alignment in reasoning and self-improvement has always fascinated me. I would like to explore these directions further when I have more time and resources.
